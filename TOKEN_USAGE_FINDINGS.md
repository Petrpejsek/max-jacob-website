# Token Usage - PrvotnÃ­ NÃ¡lezy & DoporuÄenÃ­

## ğŸ” Co jsem zkontroloval

Analyzoval jsem celou LLM pipeline a identifikoval jsem:

1. **Strukturu volÃ¡nÃ­:** 6 asistentÅ¯ v sekvenci/paralelnÄ›
2. **Velikosti payloadÅ¯:** Co se posÃ­lÃ¡ do kaÅ¾dÃ©ho asistenta
3. **PotenciÃ¡lnÃ­ duplicity:** Kde se data opakujÃ­ zbyteÄnÄ›
4. **OptimalizaÄnÃ­ pÅ™Ã­leÅ¾itosti:** Co by Å¡lo zmenÅ¡it

---

## ğŸ“Š Struktura Pipeline

```
STAGE 1:
  A1: Evidence Normalizer
    Input: evidence_pack_v2 + raw_dump (8 pages) + screenshots
    Output: llm_context_json

STAGE 2 (paralelnÄ›):
  A2: UX Auditor
    Input: llm_context + raw_dump + screenshots
    
  A3: SEO Auditor
    Input: llm_context + raw_dump

STAGE 3:
  A4: Offer Strategist
    Input: llm_context + ux_audit + seo_audit

STAGE 4 (paralelnÄ›):
  A5: Email Writer
    Input: llm_context + offer_copy + links
    
  A6: Public Page Composer
    Input: llm_context + ux_audit + seo_audit + offer_copy + screenshots + compliance + links
```

---

## ğŸš¨ DetekovanÃ© PotenciÃ¡lnÃ­ ProblÃ©my

### 1. **raw_dump se posÃ­lÃ¡ do 3 asistentÅ¯**

**Co se dÄ›je:**
- A1 dostÃ¡vÃ¡ `raw_dump` (8 pages, trimmed) - **NUTNÃ‰**
- A2 dostÃ¡vÃ¡ `raw_dump` (8 pages, trimmed) - **MOÅ½NÃ ZBYTEÄŒNÃ‰?**
- A3 dostÃ¡vÃ¡ `raw_dump` (8 pages, trimmed) - **ÄŒÃSTEÄŒNÄš ZBYTEÄŒNÃ‰?**

**Velikost:**
- `raw_dump` per page: ~10-15 KB
- 8 pages Ã— 3 assistants = **~240-360 KB poslÃ¡no 3Ã—**

**DoporuÄenÃ­:**
- âœ… **A1 potÅ™ebuje full raw_dump** - nechej tak
- â“ **A2 (UX Auditor)**: Zkontroluj prompt - moÅ¾nÃ¡ staÄÃ­ jen `llm_context` (to je output A1, kterÃ½ uÅ¾ je normalized). Pokud nepotÅ™ebuje raw data, odstraÅˆ `raw_dump` z A2 payloadu.
- âš ï¸  **A3 (SEO Auditor)**: PotÅ™ebuje `jsonld_raw` a moÅ¾nÃ¡ city mentions z pages. MÃ­sto celÃ©ho `raw_dump` by mohl dostat jen:
  ```javascript
  raw_dump_minimal: {
    jsonld_raw: raw_dump.jsonld_raw,
    jsonld_extracted: raw_dump.jsonld_extracted,
    page_titles: pages.map(p => p.title) // Pro city detection
  }
  ```

**PotenciÃ¡lnÃ­ Ãºspora:** **~150-240 KB** (2Ã— raw_dump)

---

### 2. **A6 dostÃ¡vÃ¡ VÅ ECHNO**

**Co se dÄ›je:**
A6 (Public Page Composer) dostÃ¡vÃ¡:
- `llm_context` (output A1)
- `ux_audit_json` (output A2) - **celÃ½ objekt**
- `local_seo_audit_json` (output A3) - **celÃ½ objekt**
- `offer_copy_json` (output A4)
- `screenshots`
- `compliance` rules
- `links`

**Velikost:**
- `ux_audit_json`: ~15-25 KB
- `local_seo_audit_json`: ~10-20 KB
- Celkem A6 payload: **~80-120 KB**

**ProblÃ©m:**
A6 vytvÃ¡Å™Ã­ public page, takÅ¾e potÅ™ebuje jen:
- Z `ux_audit_json`: `top_issues` (max 3-5 items)
- Z `local_seo_audit_json`: moÅ¾nÃ¡ `nap_audit.status` a zÃ¡kladnÃ­ scores
- Ale dostÃ¡vÃ¡ **celÃ© objekty** vÄetnÄ› vÅ¡ech scores, vÅ¡ech mobile_issues, vÅ¡ech detailÅ¯

**DoporuÄenÃ­:**
VytvoÅ™ `trimmed` verze auditÅ¯ pro A6:

```javascript
// V buildA6Payload():
const trimmedUxAudit = {
  top_issues: ux_audit_json.top_issues?.slice(0, 3) || [],
  scores: ux_audit_json.scores || {}
};

const trimmedSeoAudit = {
  nap_audit: local_seo_audit_json.nap_audit || {},
  scores: local_seo_audit_json.scores || {}
};
```

**PotenciÃ¡lnÃ­ Ãºspora:** **~15-30 KB**

---

### 3. **evidence_pack_v2 mÅ¯Å¾e bÃ½t velkÃ½**

**Co se dÄ›je:**
`evidence_pack_v2` jde do A1 (Evidence Normalizer) a mÅ¯Å¾e obsahovat:
- VelkÃ© arrays (`services`, `trust_signals`, atd.)
- RedundantnÃ­ data
- DlouhÃ© text snippety

**Velikost:**
- Typicky: 30-80 KB
- V extrÃ©mnÃ­ch pÅ™Ã­padech: >100 KB

**DoporuÄenÃ­:**
Zkontroluj `evidence_pack_v2` strukturu a:
- Omez `text_snippet` na kaÅ¾dÃ©m service/trust signal na max 200-300 znakÅ¯
- Omez arrays (napÅ™. max 20 services, max 15 trust signals)
- OdstraÅˆ redundantnÃ­ metadata

**PotenciÃ¡lnÃ­ Ãºspora:** **~10-20 KB**

---

### 4. **text_snippet v raw_dump pages**

**Co se dÄ›je:**
KaÅ¾dÃ¡ page v `raw_dump` mÃ¡ `text_snippet` oÅ™Ã­znutÃ½ na **1200 znakÅ¯**.

**Velikost:**
- 1200 znakÅ¯ Ã— 8 pages = **9,600 znakÅ¯** = ~2,400 tokenÅ¯

**DoporuÄenÃ­:**
- ZkraÅ¥ na **600-800 znakÅ¯** per page (stÃ¡le dost pro kontext)
- Nebo poÅ¡li full snippet jen pro **homepage + top 3 pages**

**PotenciÃ¡lnÃ­ Ãºspora:** **~1,000-1,500 tokenÅ¯** (input)

---

### 5. **Headings arrays v raw_dump**

**Co se dÄ›je:**
```javascript
headings: {
  h1: headings.h1 || null,
  h2: Array.isArray(headings.h2) ? headings.h2.slice(0, 10) : [],
  h3: Array.isArray(headings.h3) ? headings.h3.slice(0, 15) : [],
  h6: Array.isArray(headings.h6) ? headings.h6.slice(0, 15) : []
}
```

**ProblÃ©m:**
- 10 h2 + 15 h3 + 15 h6 = **40 headings per page**
- 8 pages Ã— 40 headings = **320 headings**

**DoporuÄenÃ­:**
- ZkraÅ¥ na: `h2: slice(0, 5)`, `h3: slice(0, 8)`, `h6: slice(0, 5)`
- H6 jsou Äasto navigaÄnÃ­/footer links - moÅ¾nÃ¡ ÃºplnÄ› vynechat

**PotenciÃ¡lnÃ­ Ãºspora:** **~500-800 tokenÅ¯**

---

## ğŸ’° OdhadovanÃ© CelkovÃ© Ãšspory

Pokud implementujeÅ¡ vÅ¡echny optimalizace:

| Optimalizace | Ãšspora tokenÅ¯ | Ãšspora $ per job |
|-------------|---------------|------------------|
| OdstranÄ›nÃ­ raw_dump z A2 | ~20,000 | $0.06 |
| ZmenÅ¡enÃ­ raw_dump pro A3 | ~15,000 | $0.045 |
| Trimmed audits pro A6 | ~5,000 | $0.015 |
| KratÅ¡Ã­ text_snippet | ~1,500 | $0.0045 |
| MÃ©nÄ› headings | ~800 | $0.0024 |
| **CELKEM** | **~42,300** | **~$0.127** |

**PÅ™i 100 jobÅ¯/mÄ›sÃ­c:**
- Ãšspora: **~4.2M tokenÅ¯**
- Ãšspora: **~$12.70/mÄ›sÃ­c**

**PÅ™i 1000 jobÅ¯/mÄ›sÃ­c:**
- Ãšspora: **~42M tokenÅ¯**
- Ãšspora: **~$127/mÄ›sÃ­c**

---

## âœ… Co Je SprÃ¡vnÄ› (Nech Tak)

1. **`trimRawDumpForAssistants()` uÅ¾ existuje** - dobÅ™e!
   - Omezuje na 8 pages (ne vÅ¡echny)
   - Omezuje headings arrays
   - Omezuje text_snippet na 1200 chars

2. **`normalizeScreenshotsForAssistants()` jen posÃ­lÃ¡ refs** - dobÅ™e!
   - NeposÃ­lÃ¡ base64 images, jen URLs/cesty

3. **Payload builders jsou separÃ¡tnÃ­** - dobÅ™e!
   - KaÅ¾dÃ½ assistant mÃ¡ vlastnÃ­ payload builder
   - SnadnÃ¡ customizace per assistant

4. **Token usage se uÅ¾ trackuje v DB** - dobÅ™e!
   - `assistant_runs.token_usage_json`
   - Data uÅ¾ jsou k dispozici

---

## ğŸ› ï¸ ImplementaÄnÃ­ PlÃ¡n

### FÃ¡ze 1: Monitoring (HOTOVO âœ…)
- [x] Token analytics modul vytvoÅ™en
- [x] AutomatickÃ© logovÃ¡nÃ­ zapnuto
- [x] CLI nÃ¡stroje pro analÃ½zu
- [x] DiagnostickÃ© scripty

### FÃ¡ze 2: AnalÃ½za (NYNÃ)
1. SpusÅ¥ 5-10 reÃ¡lnÃ½ch auditÅ¯
2. Zkontroluj logy v `logs/token-analytics/`
3. SpusÅ¥: `node scripts/analyze-token-usage.js`
4. OvÄ›Å™, kterÃ© optimalizace jsou prioritnÃ­

### FÃ¡ze 3: Optimalizace (PO ANALÃZE)
**Pouze pokud analytics potvrdÃ­ problÃ©my:**

1. **High Priority:**
   - OdstranÄ›nÃ­ `raw_dump` z A2 (pokud prompt nepotÅ™ebuje)
   - ZmenÅ¡enÃ­ `raw_dump` pro A3 (jen jsonld + titles)

2. **Medium Priority:**
   - Trimmed audits pro A6
   - KratÅ¡Ã­ text_snippet (800 chars)

3. **Low Priority:**
   - MÃ©nÄ› headings v raw_dump
   - Optimalizace evidence_pack_v2

### FÃ¡ze 4: MÄ›Å™enÃ­ (PO OPTIMALIZACI)
1. SpusÅ¥ dalÅ¡Ã­ch 5-10 auditÅ¯
2. Porovnej s FÃ¡zÃ­ 2
3. OvÄ›Å™ Ãºspory

---

## ğŸ“ Jak Analyzovat

### 1. Zkontroluj existujÃ­cÃ­ job
```bash
# Najdi job ID v databÃ¡zi
sqlite3 data.db "SELECT id, input_url, status FROM audit_jobs ORDER BY id DESC LIMIT 10"

# Inspektuj payload sizes
node scripts/inspect-payload-size.js 123
```

### 2. SpusÅ¥ novÃ½ audit s analyticsou
```bash
# Analytics je automaticky zapnutÃ¡
# Sleduj console output bÄ›hem audit pipeline
```

### 3. Zkontroluj reports
```bash
# SouhrnnÃ½ report
node scripts/analyze-token-usage.js

# Detail pro konkrÃ©tnÃ­ho asistenta
node scripts/analyze-token-usage.js --assistant evidence_normalizer
```

### 4. Zkontroluj logy
```bash
# Najdi nejnovÄ›jÅ¡Ã­ report
ls -lt logs/token-analytics/ | head -5

# OtevÅ™i v JSON vieweru
cat logs/token-analytics/job-123-*.json | jq
```

---

## âš ï¸ DÅ¯leÅ¾itÃ© PoznÃ¡mky

### PÅ™ed optimalizacÃ­ VÅ½DY ovÄ›Å™:
1. **PotÅ™ebuje LLM tato data?** - Zkontroluj prompt kaÅ¾dÃ©ho asistenta
2. **ZhorÅ¡Ã­ se kvalita outputu?** - Otestuj na 5-10 jobech
3. **Je to opravdu duplicita?** - MoÅ¾nÃ¡ kaÅ¾dÃ½ assistant potÅ™ebuje jinÃ½ view na data

### Neoptimalizuj slepÄ›:
- Pokud `raw_dump` v A2 zlepÅ¡uje UX audit â†’ nech tam
- Pokud trimmed audits v A6 snÃ­Å¾Ã­ kvalitu public page â†’ nech celÃ©
- Prioritizuj **kvalitu pÅ™ed Ãºsporami**

### MÄ›Å™, nehadej:
- SpusÅ¥ analytics minimÃ¡lnÄ› na 20 jobech
- Sleduj trendy, ne jednotlivÃ© vÃ½kyvy
- Porovnej pÅ™ed/po kaÅ¾dÃ© optimalizaci

---

## ğŸ¯ ZÃ¡vÄ›r

**Implementoval jsem:**
âœ… KompletnÃ­ token analytics modul (neinvazivnÃ­)  
âœ… AutomatickÃ© logovÃ¡nÃ­ pÅ™i kaÅ¾dÃ©m auditu  
âœ… CLI nÃ¡stroje pro analÃ½zu  
âœ… DiagnostickÃ© scripty  
âœ… Dokumentaci

**Co dÃ¡l:**
1. **SpusÅ¥ pÃ¡r auditÅ¯** a sleduj logy
2. **Zkontroluj detekovanÃ© duplicity** - jsou reÃ¡lnÃ©?
3. **Implementuj optimalizace** postupnÄ› (high priority first)
4. **MÄ›Å™ vÃ½sledky** pÅ™ed/po kaÅ¾dÃ© zmÄ›nÄ›

**NemÄ›nil jsem:**
âŒ Å½Ã¡dnÃ½ existujÃ­cÃ­ kÃ³d (kromÄ› 3 Å™Ã¡dkÅ¯ pro tracking)  
âŒ Å½Ã¡dnÃ© payloady  
âŒ Å½Ã¡dnÃ© prompty  
âŒ Å½Ã¡dnou funkcionalitu

VÅ¡echno je pÅ™ipraveno na diagnostiku. TeÄ je Äas spustit pÃ¡r auditÅ¯ a podÃ­vat se na reÃ¡lnÃ¡ ÄÃ­sla! ğŸš€
