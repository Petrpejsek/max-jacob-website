# Token Analytics - Souhrn Implementace

## âœ… Co jsem udÄ›lal

### 1. VytvoÅ™il jsem **neinvazivnÃ­ analytickÃ½ modul** (`tokenAnalytics.js`)

**Funkce:**
- âœ… Sleduje velikosti payloadÅ¯ pÅ™ed odeslÃ¡nÃ­m do LLM
- âœ… Loguje skuteÄnÃ© token usage z API response
- âœ… Detekuje duplicitnÃ­/redundantnÃ­ data
- âœ… PoÄÃ­tÃ¡ nÃ¡klady per assistant a per job
- âœ… Generuje detailnÃ­ reporty do JSON souborÅ¯
- âœ… Vypisuje warnings do konzole bÄ›hem bÄ›hu

**DÅ¯leÅ¾itÃ©:** NeuklÃ¡dÃ¡ sensitive data, jen velikosti a ÄÃ­sla!

---

### 2. Integroval jsem tracking do existujÃ­cÃ­ho pipeline

**ZmÄ›ny v `auditPipeline.js`:**
- â• Import analytickÃ©ho modulu (1 Å™Ã¡dek)
- â• VolÃ¡nÃ­ `trackPayload()` pÅ™ed LLM call (1 Å™Ã¡dek)
- â• VolÃ¡nÃ­ `trackResponse()` po LLM response (1 Å™Ã¡dek)
- â• VolÃ¡nÃ­ `generateJobReport()` na konci pipeline (1 Å™Ã¡dek)

**Celkem: 4 Å™Ã¡dky kÃ³du pÅ™idÃ¡ny, nic zmÄ›nÄ›no!**

---

### 3. VytvoÅ™il jsem CLI nÃ¡stroje

**`scripts/analyze-token-usage.js`** - SouhrnnÃ© reporty
```bash
# ZÃ¡kladnÃ­ pÅ™ehled (poslednÃ­ch 100 jobÅ¯)
node scripts/analyze-token-usage.js

# Jen nedÃ¡vnÃ© joby (24h)
node scripts/analyze-token-usage.js --recent

# Detail pro konkrÃ©tnÃ­ho asistenta
node scripts/analyze-token-usage.js --assistant evidence_normalizer
```

**`scripts/inspect-payload-size.js`** - Diagnostika konkrÃ©tnÃ­ho jobu
```bash
# UkÃ¡Å¾e payload sizes pro job ID 123 (bez spuÅ¡tÄ›nÃ­ LLM)
node scripts/inspect-payload-size.js 123
```

---

### 4. PÅ™idal jsem dokumentaci

- **`TOKEN_ANALYTICS_README.md`** - KompletnÃ­ nÃ¡vod
- **`TOKEN_USAGE_FINDINGS.md`** - DetekovanÃ© problÃ©my + doporuÄenÃ­
- **`TOKEN_ANALYTICS_SOUHRN.md`** - Tento dokument

---

## ğŸ” Co jsem naÅ¡el (bez spuÅ¡tÄ›nÃ­, jen analÃ½zou kÃ³du)

### PotenciÃ¡lnÃ­ optimalizace:

1. **`raw_dump` se posÃ­lÃ¡ do 3 asistentÅ¯** (A1, A2, A3)
   - A2 moÅ¾nÃ¡ nepotÅ™ebuje (mÃ¡ `llm_context` z A1)
   - A3 potÅ™ebuje jen ÄÃ¡st (`jsonld_raw`)
   - **MoÅ¾nÃ¡ Ãºspora: ~35,000 tokenÅ¯ per job**

2. **A6 dostÃ¡vÃ¡ kompletnÃ­ audit vÃ½stupy**
   - PotÅ™ebuje jen `top_issues`, ne celÃ½ objekt
   - **MoÅ¾nÃ¡ Ãºspora: ~5,000 tokenÅ¯ per job**

3. **`text_snippet` je 1200 znakÅ¯ per page**
   - MoÅ¾nÃ¡ staÄÃ­ 600-800 znakÅ¯
   - **MoÅ¾nÃ¡ Ãºspora: ~1,500 tokenÅ¯ per job**

4. **HodnÄ› headings v arrays**
   - h2: 10, h3: 15, h6: 15 per page
   - **MoÅ¾nÃ¡ Ãºspora: ~800 tokenÅ¯ per job**

**Celkem moÅ¾nÃ¡ Ãºspora: ~42,000 tokenÅ¯ per job (~$0.127)**

---

## ğŸš€ Jak to pouÅ¾Ã­t?

### Krok 1: SpusÅ¥ pÃ¡r auditÅ¯ normÃ¡lnÄ›

Analytics je **automaticky zapnutÃ¡**. PÅ™i bÄ›hu pipeline uvidÃ­Å¡ v konzoli:

```
[TokenAnalytics] evidence_normalizer - Payload: 142.5 KB, Est. ~18,450 tokens
[TokenAnalytics] âš ï¸  Large payload: ~18,450 estimated input tokens
[TokenAnalytics] ğŸ” Potential optimizations:
   - raw_dump data is being sent (check if needed) (85.2 KB)
...
[TokenAnalytics] evidence_normalizer - Actual tokens: 19,234 (input: 18,892, output: 342), Cost: $0.0623
...
================================================================================
[TokenAnalytics] JOB REPORT - Job ID: 123
================================================================================
Total Assistants: 6
Total Estimated Input Tokens: 45,230
Total Actual Tokens: 52,180
Total Cost: $0.1956
...
```

### Krok 2: Zkontroluj logy

```bash
# Najdi nejnovÄ›jÅ¡Ã­ reporty
ls -lt logs/token-analytics/

# OtevÅ™i jeden report
cat logs/token-analytics/job-123-*.json | jq
```

### Krok 3: Vygeneruj souhrnnÃ½ report

```bash
# Po 20-30 auditech spusÅ¥
node scripts/analyze-token-usage.js

# UvidÃ­Å¡ prÅ¯mÄ›ry, trendy, nejÄastÄ›jÅ¡Ã­ duplicity
```

### Krok 4: Diagnostika konkrÃ©tnÃ­ho jobu

```bash
# Pokud jeden job vypadÃ¡ divnÄ›
node scripts/inspect-payload-size.js 123

# UkÃ¡Å¾e ti pÅ™esnÄ›, co se posÃ­lÃ¡ do kaÅ¾dÃ©ho asistenta
```

---

## âš™ï¸ Konfigurace

### Vypnout analytics (pro production?)

V `.env`:
```
TOKEN_ANALYTICS_ENABLED=false
```

### ZmÄ›nit ceny (pokud pouÅ¾Ã­vÃ¡Å¡ jinÃ½ model)

V `server/services/tokenAnalytics.js`:
```javascript
const COST_PER_1M_INPUT_TOKENS = 3.0;   // USD
const COST_PER_1M_OUTPUT_TOKENS = 15.0; // USD
```

---

## ğŸ“Š Co analytics detekuje?

### Automaticky:

âœ… **DuplicitnÃ­ data:**
- `raw_dump` v multiple payloads
- StejnÃ¡ data poslanÃ¡ vÃ­cekrÃ¡t

âœ… **VelkÃ© payloady:**
- Payload > 50KB dostane warning
- Evidence pack > 50KB
- LLM context > 30KB

âœ… **Multiple audit outputs:**
- KdyÅ¾ payload obsahuje >2 audit vÃ½stupy najednou

âœ… **PorovnÃ¡nÃ­ odhad vs. skuteÄnost:**
- OvÄ›Å™uje, jestli jsou odhady tokenÅ¯ pÅ™esnÃ©

### V reportech:

- NejvÄ›tÅ¡Ã­ payload (kterÃ½ assistant, kolik KB)
- NejdraÅ¾Å¡Ã­ assistant (kterÃ½, kolik $)
- VÅ¡echny detekovanÃ© duplicity
- VÅ¡echny warnings
- Trendy v Äase (aggregate report)

---

## ğŸ¯ DalÅ¡Ã­ kroky

### NynÃ­:
1. âœ… SpusÅ¥ 10-20 auditÅ¯ s rÅ¯znÃ½mi niches/cities
2. âœ… Sleduj console output - vidÃ­Å¡ nÄ›jakÃ© problÃ©my?
3. âœ… Zkontroluj logy v `logs/token-analytics/`
4. âœ… SpusÅ¥ `node scripts/analyze-token-usage.js`

### Pokud analytics potvrdÃ­ problÃ©my:
5. âš ï¸  Zkontroluj assistant prompty - potÅ™ebujÃ­ opravdu vÅ¡echna data?
6. âš ï¸  Implementuj optimalizace postupnÄ› (high priority first)
7. âš ï¸  MÄ›Å™ pÅ™ed/po kaÅ¾dÃ© zmÄ›nÄ›
8. âš ï¸  OvÄ›Å™, Å¾e kvalita outputu neklesla

### DlouhodobÄ›:
9. ğŸ”„ PravidelnÄ› spouÅ¡tÄ›j aggregate report (1Ã— tÃ½dnÄ›?)
10. ğŸ”„ Sleduj trendy - roste spotÅ™eba?
11. ğŸ”„ KdyÅ¾ pÅ™idÃ¡vÃ¡Å¡ novÃ© featury, zkontroluj dopad na tokeny

---

## âš ï¸ DÅ¯leÅ¾itÃ©!

### NEOPRAVUJ NIC SLEPÄš

Analytics **jen detekuje** potenciÃ¡lnÃ­ problÃ©my. PÅ™ed kaÅ¾dou optimalizacÃ­:

1. **OvÄ›Å™ v promptu** - potÅ™ebuje LLM tato data?
2. **Otestuj na 5-10 jobech** - neklesne kvalita?
3. **MÄ›Å™ pÅ™ed/po** - byla Ãºspora skuteÄnÃ¡?

### Prioritizuj KVALITU pÅ™ed Ãºsporami

Pokud `raw_dump` v A2 zlepÅ¡uje vÃ½sledky â†’ **nech tam**.  
Pokud trimmed audits v A6 snÃ­Å¾Ã­ kvalitu â†’ **nech celÃ©**.  

CÃ­l je najÃ­t **WIN-WIN**: stejnÃ¡ kvalita, niÅ¾Å¡Ã­ nÃ¡klady.

---

## ğŸ“ VytvoÅ™enÃ© soubory

```
server/services/
  â””â”€â”€ tokenAnalytics.js           # HlavnÃ­ modul (570 Å™Ã¡dkÅ¯)

scripts/
  â”œâ”€â”€ analyze-token-usage.js      # CLI: aggregate reports
  â””â”€â”€ inspect-payload-size.js     # CLI: payload diagnostics

logs/
  â””â”€â”€ token-analytics/            # JSON reporty (gitignored)

docs:
  â”œâ”€â”€ TOKEN_ANALYTICS_README.md   # KompletnÃ­ nÃ¡vod
  â”œâ”€â”€ TOKEN_USAGE_FINDINGS.md     # DetekovanÃ© problÃ©my
  â””â”€â”€ TOKEN_ANALYTICS_SOUHRN.md   # Tento souhrn
```

---

## ğŸ§ª TestovÃ¡nÃ­

VÅ¡echny soubory proÅ¡ly syntax check:
```bash
âœ… tokenAnalytics.js - OK
âœ… auditPipeline.js - OK
âœ… analyze-token-usage.js - OK
âœ… inspect-payload-size.js - OK
```

Å½Ã¡dnÃ© linter errors!

---

## ğŸ’¡ Tip: PrvnÃ­ test

Zkus spustit inspector na existujÃ­cÃ­m jobu:

```bash
# Najdi job ID
sqlite3 data.db "SELECT id, input_url FROM audit_jobs WHERE status='completed' ORDER BY id DESC LIMIT 5"

# Inspektuj payload sizes
node scripts/inspect-payload-size.js <job_id>
```

UvidÃ­Å¡, kolik KB a tokenÅ¯ se posÃ­lÃ¡ do kaÅ¾dÃ©ho asistenta **BEZ spuÅ¡tÄ›nÃ­ LLM**.

---

Hotovo! MÃ¡Å¡ kompletnÃ­ diagnostickÃ½ systÃ©m bez zmÄ›ny funkcionality. TeÄ je Äas sbÃ­rat data a hledat optimalizace! ğŸš€
